{
  "1": {
    "inputs": {
      "image": "%%IMAGE1%%",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "åŠ è½½å›¾åƒ"
    }
  },
  "4": {
    "inputs": {
      "image": [
        "1",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "ğŸ”§ Get Image Size"
    }
  },
  "7": {
    "inputs": {
      "expand": 20,
      "incremental_expandrate": 0,
      "tapered_corners": true,
      "flip_input": false,
      "blur_radius": 20,
      "lerp_alpha": 1,
      "decay_factor": 1,
      "fill_holes": false,
      "mask": [
        "1",
        1
      ]
    },
    "class_type": "GrowMaskWithBlur",
    "_meta": {
      "title": "Grow Mask With Blur"
    }
  },
  "9": {
    "inputs": {
      "model": [
        "33",
        0
      ]
    },
    "class_type": "DifferentialDiffusion",
    "_meta": {
      "title": "å·®å¼‚æ‰©æ•£DifferentialDiffusion"
    }
  },
  "10": {
    "inputs": {
      "seed": 697631191461672,
      "steps": 32,
      "cfg": 4.5,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "9",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "11",
        1
      ],
      "latent_image": [
        "11",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Ké‡‡æ ·å™¨"
    }
  },
  "11": {
    "inputs": {
      "noise_mask": true,
      "positive": [
        "13",
        0
      ],
      "negative": [
        "13",
        1
      ],
      "vae": [
        "33",
        2
      ],
      "pixels": [
        "32",
        0
      ],
      "mask": [
        "7",
        0
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "å†…è¡¥æ¨¡å‹æ¡ä»¶"
    }
  },
  "12": {
    "inputs": {
      "control_net_name": "SDXL/diffusion_pytorch_model.fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "åŠ è½½ControlNetæ¨¡å‹"
    }
  },
  "13": {
    "inputs": {
      "strength": 0.4,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "14",
        0
      ],
      "negative": [
        "15",
        0
      ],
      "control_net": [
        "12",
        0
      ],
      "image": [
        "18",
        0
      ],
      "vae": [
        "33",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "åº”ç”¨ControlNetï¼ˆæ—§ç‰ˆé«˜çº§ï¼‰"
    }
  },
  "14": {
    "inputs": {
      "text": "%%PROMPT1%%",
      "clip": [
        "33",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIPæ–‡æœ¬ç¼–ç "
    }
  },
  "15": {
    "inputs": {
      "text": "Colorful, Overexposed, Blurred details, Subtitles, Overall gray, Worst quality, Low quality, JPEG compression residue, Ugly, Mutilated, Extra fingers, Badly drawn hands, Badly drawn faces, Deformed, Disfigured, Deformed limbs, Fused fingers, Three legs",
      "clip": [
        "33",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIPæ–‡æœ¬ç¼–ç "
    }
  },
  "16": {
    "inputs": {
      "samples": [
        "10",
        0
      ],
      "vae": [
        "33",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAEè§£ç "
    }
  },
  "18": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": 512,
      "image": [
        "32",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "Depth Anything V2 - Relative"
    }
  },
  "30": {
    "inputs": {
      "value": "round(a / 8)*8",
      "a": [
        "4",
        0
      ]
    },
    "class_type": "SimpleMath+",
    "_meta": {
      "title": "ğŸ”§ Simple Math"
    }
  },
  "31": {
    "inputs": {
      "value": "round(a / 8)*8",
      "a": [
        "4",
        1
      ]
    },
    "class_type": "SimpleMath+",
    "_meta": {
      "title": "ğŸ”§ Simple Math"
    }
  },
  "32": {
    "inputs": {
      "width": [
        "30",
        0
      ],
      "height": [
        "31",
        0
      ],
      "interpolation": "lanczos",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "1",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ğŸ”§ Image Resize"
    }
  },
  "33": {
    "inputs": {
      "ckpt_name": "SDXL-TURBO/sd_xl_turbo_1.0_fp16.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "CheckpointåŠ è½½å™¨ï¼ˆç®€æ˜“ï¼‰"
    }
  },
  "43": {
    "inputs": {
      "expand": 20,
      "incremental_expandrate": 0,
      "tapered_corners": true,
      "flip_input": false,
      "blur_radius": 20,
      "lerp_alpha": 1,
      "decay_factor": 1,
      "fill_holes": false,
      "mask": [
        "1",
        1
      ]
    },
    "class_type": "GrowMaskWithBlur",
    "_meta": {
      "title": "Grow Mask With Blur"
    }
  },
  "44": {
    "inputs": {
      "model": [
        "56",
        0
      ]
    },
    "class_type": "DifferentialDiffusion",
    "_meta": {
      "title": "å·®å¼‚æ‰©æ•£DifferentialDiffusion"
    }
  },
  "45": {
    "inputs": {
      "seed": 1005773912989945,
      "steps": 32,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "44",
        0
      ],
      "positive": [
        "46",
        0
      ],
      "negative": [
        "46",
        1
      ],
      "latent_image": [
        "46",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Ké‡‡æ ·å™¨"
    }
  },
  "46": {
    "inputs": {
      "noise_mask": true,
      "positive": [
        "48",
        0
      ],
      "negative": [
        "48",
        1
      ],
      "vae": [
        "57",
        0
      ],
      "pixels": [
        "32",
        0
      ],
      "mask": [
        "43",
        0
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "å†…è¡¥æ¨¡å‹æ¡ä»¶"
    }
  },
  "47": {
    "inputs": {
      "control_net_name": "FLUX.1/FLUX.1-dev-ControlNet-Union-Pro/diffusion_pytorch_model.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "åŠ è½½ControlNetæ¨¡å‹"
    }
  },
  "48": {
    "inputs": {
      "strength": 0.4,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "101",
        0
      ],
      "negative": [
        "50",
        0
      ],
      "control_net": [
        "59",
        0
      ],
      "image": [
        "53",
        0
      ],
      "vae": [
        "57",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "åº”ç”¨ControlNetï¼ˆæ—§ç‰ˆé«˜çº§ï¼‰"
    }
  },
  "49": {
    "inputs": {
      "text": "%%PROMPT1%%",
      "clip": [
        "58",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIPæ–‡æœ¬ç¼–ç "
    }
  },
  "50": {
    "inputs": {
      "text": "Colorful, Overexposed, Blurred details, Subtitles, Overall gray, Worst quality, Low quality, JPEG compression residue, Ugly, Mutilated, Extra fingers, Badly drawn hands, Badly drawn faces, Deformed, Disfigured, Deformed limbs, Fused fingers, Three legs",
      "clip": [
        "58",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIPæ–‡æœ¬ç¼–ç "
    }
  },
  "51": {
    "inputs": {
      "samples": [
        "45",
        0
      ],
      "vae": [
        "57",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAEè§£ç "
    }
  },
  "52": {
    "inputs": {
      "images": [
        "51",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "é¢„è§ˆå›¾åƒ"
    }
  },
  "53": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": 512,
      "image": [
        "32",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "Depth Anything V2 - Relative"
    }
  },
  "56": {
    "inputs": {
      "unet_name": "flux1-dev-Q4_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "57": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "åŠ è½½VAE"
    }
  },
  "58": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "åŒCLIPåŠ è½½å™¨"
    }
  },
  "59": {
    "inputs": {
      "type": "depth",
      "control_net": [
        "47",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "è®¾ç½®UnionControlNetç±»å‹"
    }
  },
  "101": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "49",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "Fluxå¼•å¯¼"
    }
  }
}